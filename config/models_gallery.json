{
  "version": "1.0",
  "generatedAt": "2024-10-01T00:00:00Z",
  "models": [
    {
      "id": "llama-3.2-3b-q4",
      "name": "Llama 3.2 3B Q4",
      "categories": [
        "chat",
        "general"
      ],
      "checksum": "sha256:4cb1444f81355e47d236ada8190f0325ce46412a83f3ab62a1d63bb314592ebc",
      "downloadUrl": "https://huggingface.co/bartowski/Llama-3.2-3B-Instruct-GGUF/resolve/main/Llama-3.2-3B-Instruct-Q4_K_M.gguf",
      "languages": [
        "en",
        "de"
      ],
      "recommendedHardware": {
        "cpu": "8-core",
        "gpu": "CPU",
        "ramGb": 16,
        "vramGb": 0
      },
      "parameters": "3B",
      "sizeGb": 1.8,
      "rating": 4.2,
      "license": "Meta",
      "description": "CPU-freundliches Llama 3.2 3B Q4 für allgemeine Aufgaben.",
      "tags": [
        "tier-1",
        "cpu-friendly"
      ],
      "quantization": "Q4",
      "contextLength": 8192,
      "updatedAt": "2024-10-01"
    },
    {
      "id": "llama-3.1-8b-q5",
      "name": "Llama 3.1 8B Q5",
      "categories": [
        "chat",
        "general"
      ],
      "checksum": "sha256:fb984c9153528e2ffbd10149938fa53e0dfcece23511bd698c3691236d470110",
      "downloadUrl": "https://huggingface.co/bartowski/Meta-Llama-3.1-8B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-8B-Instruct-Q5_K_M.gguf",
      "languages": [
        "en",
        "de"
      ],
      "recommendedHardware": {
        "cpu": "12-core",
        "gpu": "NVIDIA RTX 3060",
        "ramGb": 24,
        "vramGb": 12
      },
      "parameters": "8B",
      "sizeGb": 4.6,
      "rating": 4.6,
      "license": "Meta",
      "description": "Balanciertes Llama 3.2 8B Q5 für Qualität und Geschwindigkeit.",
      "tags": [
        "tier-1",
        "balanced"
      ],
      "quantization": "Q5",
      "contextLength": 8192,
      "updatedAt": "2024-10-01"
    },
    {
      "id": "mistral-7b-v0.3-q5",
      "name": "Mistral 7B Instruct Q5",
      "categories": [
        "chat",
        "instruction"
      ],
      "checksum": "sha256:3ec16208cd105516e5559cecbeb263bc41d8844f32dfc459d4b40f37a951b5a1",
      "downloadUrl": "https://huggingface.co/bartowski/Mistral-7B-Instruct-v0.3-GGUF/resolve/main/Mistral-7B-Instruct-v0.3-Q5_K_M.gguf",
      "languages": [
        "en",
        "fr"
      ],
      "recommendedHardware": {
        "cpu": "12-core",
        "gpu": "NVIDIA RTX 3060",
        "ramGb": 24,
        "vramGb": 12
      },
      "parameters": "7B",
      "sizeGb": 4.2,
      "rating": 4.5,
      "license": "Apache-2.0",
      "description": "Chat-spezialisiertes Mistral 7B Instruct Q5.",
      "tags": [
        "tier-1",
        "chat"
      ],
      "quantization": "Q5",
      "contextLength": 8192,
      "updatedAt": "2024-10-01"
    },
    {
      "id": "llama-3.2-3b-instruct-q4",
      "name": "Llama 3.2 3B Instruct Q4",
      "categories": [
        "chat",
        "instruction"
      ],
      "checksum": "sha256:4cb1444f81355e47d236ada8190f0325ce46412a83f3ab62a1d63bb314592ebc",
      "downloadUrl": "https://huggingface.co/bartowski/Llama-3.2-3B-Instruct-GGUF/resolve/main/Llama-3.2-3B-Instruct-Q4_K_M.gguf",
      "languages": [
        "en",
        "de"
      ],
      "recommendedHardware": {
        "cpu": "8-core",
        "gpu": "CPU",
        "ramGb": 16,
        "vramGb": 0
      },
      "parameters": "3B",
      "sizeGb": 1.9,
      "rating": 4.1,
      "license": "Meta",
      "description": "Chat-optimiertes Llama 3.2 3B Instruct Q4 für CPU-Einsatz.",
      "tags": [
        "tier-1",
        "cpu"
      ],
      "quantization": "Q4",
      "contextLength": 8192,
      "updatedAt": "2024-10-01"
    },
    {
      "id": "leolm-7b-q5",
      "name": "LeoLM 7B Q5",
      "categories": [
        "chat",
        "german"
      ],
      "checksum": "sha256:d358a82380704e13052819449f43ff122cac1e0a3c9cded89f40e6bbc4adb464",
      "downloadUrl": "https://huggingface.co/TheBloke/leo-hessianai-7b-chat-GGUF/resolve/main/leo-hessianai-7b-chat.Q5_K_M.gguf",
      "languages": [
        "de",
        "en"
      ],
      "recommendedHardware": {
        "cpu": "12-core",
        "gpu": "NVIDIA RTX 3060",
        "ramGb": 24,
        "vramGb": 12
      },
      "parameters": "7B",
      "sizeGb": 4.1,
      "rating": 4.4,
      "license": "Apache-2.0",
      "description": "Deutsches LeoLM 7B Q5 für hochwertige Antworten.",
      "tags": [
        "tier-1",
        "deutsch"
      ],
      "quantization": "Q5",
      "contextLength": 8192,
      "updatedAt": "2024-10-01"
    },
    {
      "id": "codellama-7b-q5",
      "name": "CodeLlama 7B Q5",
      "categories": [
        "code",
        "development"
      ],
      "checksum": "sha256:31c44feef2d2a714c29400e4c8ccb0c086efd964af2c6889f4c0dd3ef91df979",
      "downloadUrl": "https://huggingface.co/TheBloke/CodeLlama-7B-Instruct-GGUF/resolve/main/codellama-7b-instruct.Q5_K_M.gguf",
      "languages": [
        "en"
      ],
      "recommendedHardware": {
        "cpu": "12-core",
        "gpu": "NVIDIA RTX 3060",
        "ramGb": 24,
        "vramGb": 12
      },
      "parameters": "7B",
      "sizeGb": 4.0,
      "rating": 4.3,
      "license": "Meta",
      "description": "CodeLlama 7B Q5 für Entwicklungs- und Coding-Aufgaben.",
      "tags": [
        "tier-1",
        "code"
      ],
      "quantization": "Q5",
      "contextLength": 16384,
      "updatedAt": "2024-10-01"
    },
    {
      "id": "qwen-2.5-7b-q5",
      "name": "Qwen 2.5 7B Q5",
      "categories": [
        "multilingual",
        "chat"
      ],
      "checksum": "sha256:5f47abc334aff6919f4868913b4b0b00e468e844a91aee45e527e4a145d6ea4d",
      "downloadUrl": "https://huggingface.co/bartowski/Qwen2.5-7B-Instruct-GGUF/resolve/main/Qwen2.5-7B-Instruct-Q5_K_M.gguf",
      "languages": [
        "en",
        "zh",
        "de"
      ],
      "recommendedHardware": {
        "cpu": "12-core",
        "gpu": "NVIDIA RTX 3060",
        "ramGb": 24,
        "vramGb": 12
      },
      "parameters": "7B",
      "sizeGb": 4.3,
      "rating": 4.4,
      "license": "Apache-2.0",
      "description": "Mehrsprachiges Qwen 2.5 7B Q5.",
      "tags": [
        "tier-1",
        "multilingual"
      ],
      "quantization": "Q5",
      "contextLength": 8192,
      "updatedAt": "2024-10-01"
    },
    {
      "id": "phi-3-mini-q4",
      "name": "Phi-3 Mini Q4",
      "categories": [
        "lightweight",
        "general"
      ],
      "checksum": "sha256:85f903edc555c32911e326014e229f416ca7e5c430b4b3269d18f8bb3b8c905b",
      "downloadUrl": "https://huggingface.co/bartowski/Phi-3-mini-4k-instruct-GGUF/resolve/main/Phi-3-mini-4k-instruct-Q4_K_M.gguf",
      "languages": [
        "en"
      ],
      "recommendedHardware": {
        "cpu": "6-core",
        "gpu": "CPU",
        "ramGb": 8,
        "vramGb": 0
      },
      "parameters": "3.8B",
      "sizeGb": 1.6,
      "rating": 4.0,
      "license": "MIT",
      "description": "Leichtgewichtiges Phi-3 Mini Q4 für schnelle Antworten.",
      "tags": [
        "tier-1",
        "lightweight"
      ],
      "quantization": "Q4",
      "contextLength": 4096,
      "updatedAt": "2024-10-01"
    },
    {
      "id": "gemma-2-9b-q5",
      "name": "Gemma 2 9B Q5",
      "categories": [
        "chat",
        "quality"
      ],
      "checksum": "sha256:cbd4ce17a9c3cd3157a185fc3d0c7ae8264e3ee96bc388c7bbb9c084e7243fce",
      "downloadUrl": "https://huggingface.co/bartowski/gemma-2-9b-it-GGUF/resolve/main/gemma-2-9b-it-Q5_K_M.gguf",
      "languages": [
        "en",
        "de"
      ],
      "recommendedHardware": {
        "cpu": "12-core",
        "gpu": "NVIDIA RTX 3070",
        "ramGb": 32,
        "vramGb": 12
      },
      "parameters": "9B",
      "sizeGb": 5.1,
      "rating": 4.6,
      "license": "Google",
      "description": "Qualitätsorientiertes Gemma 2 9B Q5 von Google.",
      "tags": [
        "tier-1",
        "quality"
      ],
      "quantization": "Q5",
      "contextLength": 8192,
      "updatedAt": "2024-10-01"
    },
    {
      "id": "hermes-2-pro-mistral-q5",
      "name": "Hermes 2 Pro Mistral Q5",
      "categories": [
        "function-calling",
        "chat"
      ],
      "checksum": "sha256:076ef16e1bb08eab7938ad13b4dd50c9588fb1bb9cc15c0b28dffb47d19d12ef",
      "downloadUrl": "https://huggingface.co/bartowski/Hermes-2-Pro-Mistral-7B-GGUF/resolve/main/Hermes-2-Pro-Mistral-7B-Q5_K_M.gguf",
      "languages": [
        "en"
      ],
      "recommendedHardware": {
        "cpu": "12-core",
        "gpu": "NVIDIA RTX 3060",
        "ramGb": 24,
        "vramGb": 12
      },
      "parameters": "7B",
      "sizeGb": 4.4,
      "rating": 4.5,
      "license": "MIT",
      "description": "Hermes 2 Pro Mistral Q5 mit Fokus auf Function Calling.",
      "tags": [
        "tier-1",
        "function-calling"
      ],
      "quantization": "Q5",
      "contextLength": 8192,
      "updatedAt": "2024-10-01"
    },
    {
      "id": "llama-3.1-70b-q4",
      "name": "Llama 3.1 70B Q4",
      "categories": [
        "chat",
        "flagship"
      ],
      "checksum": "sha256:273c07cdbbca671fa5e8fc091b7a012ace0e0354e04a54a2ed5cc645921c15bc",
      "downloadUrl": "https://huggingface.co/bartowski/Meta-Llama-3.1-70B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-70B-Instruct-Q4_K_M.gguf",
      "languages": [
        "en"
      ],
      "recommendedHardware": {
        "cpu": "32-core",
        "gpu": "NVIDIA A100",
        "ramGb": 128,
        "vramGb": 80
      },
      "parameters": "70B",
      "sizeGb": 38.0,
      "rating": 4.8,
      "license": "Meta",
      "description": "Flaggschiff-Modell Llama 3.1 70B Q4 für GPU-Setups.",
      "tags": [
        "tier-2",
        "gpu"
      ],
      "quantization": "Q4",
      "contextLength": 8192,
      "updatedAt": "2024-10-01"
    },
    {
      "id": "mixtral-8x7b-q4",
      "name": "Mixtral 8x7B Q4",
      "categories": [
        "moe",
        "general"
      ],
      "checksum": "sha256:a8e20676b6e2cddd808697575e20fac6e05038b315ab4035ea613df687d57ffc",
      "downloadUrl": "https://huggingface.co/MaziyarPanahi/Mixtral-8x7B-Instruct-v0.1-GGUF/resolve/main/Mixtral-8x7B-Instruct-v0.1.Q4_K_M.gguf",
      "languages": [
        "en",
        "fr"
      ],
      "recommendedHardware": {
        "cpu": "24-core",
        "gpu": "NVIDIA RTX 4090",
        "ramGb": 64,
        "vramGb": 24
      },
      "parameters": "8x7B",
      "sizeGb": 24.0,
      "rating": 4.7,
      "license": "Apache-2.0",
      "description": "Leistungsstarkes Mixtral 8x7B Q4 MoE-Modell.",
      "tags": [
        "tier-2",
        "moe"
      ],
      "quantization": "Q4",
      "contextLength": 8192,
      "updatedAt": "2024-10-01"
    },
    {
      "id": "deepseek-coder-6.7b-q5",
      "name": "DeepSeek Coder 6.7B Q5",
      "categories": [
        "code",
        "development"
      ],
      "checksum": "sha256:5855726805d9f7c9701829dad01100e0a21c55c0d7291fa2211b7f408c3af586",
      "downloadUrl": "https://huggingface.co/TheBloke/deepseek-coder-6.7b-instruct-GGUF/resolve/main/deepseek-coder-6.7b-instruct.Q5_K_M.gguf",
      "languages": [
        "en"
      ],
      "recommendedHardware": {
        "cpu": "12-core",
        "gpu": "NVIDIA RTX 3060",
        "ramGb": 24,
        "vramGb": 12
      },
      "parameters": "6.7B",
      "sizeGb": 4.1,
      "rating": 4.4,
      "license": "Apache-2.0",
      "description": "Code-spezialisiertes DeepSeek Coder 6.7B Q5.",
      "tags": [
        "tier-2",
        "code"
      ],
      "quantization": "Q5",
      "contextLength": 16384,
      "updatedAt": "2024-10-01"
    },
    {
      "id": "llama-3.2-1b-q4",
      "name": "Llama 3.2 1B Q4",
      "categories": [
        "lightweight",
        "general"
      ],
      "checksum": "sha256:7314cd624de8068beee86215e529a23665ff09e458977e32f30b8149764e7be1",
      "downloadUrl": "https://huggingface.co/bartowski/Llama-3.2-1B-Instruct-GGUF/resolve/main/Llama-3.2-1B-Instruct-Q4_K_M.gguf",
      "languages": [
        "en"
      ],
      "recommendedHardware": {
        "cpu": "4-core",
        "gpu": "CPU",
        "ramGb": 4,
        "vramGb": 0
      },
      "parameters": "1B",
      "sizeGb": 0.9,
      "rating": 3.8,
      "license": "Meta",
      "description": "Ultra-leichtes Llama 3.2 1B Q4.",
      "tags": [
        "tier-2",
        "ultra-light"
      ],
      "quantization": "Q4",
      "contextLength": 4096,
      "updatedAt": "2024-10-01"
    },
    {
      "id": "em-german-7b-q5",
      "name": "EM German 7B Q5",
      "categories": [
        "german",
        "chat"
      ],
      "checksum": "sha256:4e68cfe534d8583cbf5d6aaece5fe79f8292854741b3a07c8c9ce7a8956fbb1c",
      "downloadUrl": "https://huggingface.co/TheBloke/em_german_leo_mistral-GGUF/resolve/main/em_german_leo_mistral.Q5_K_M.gguf",
      "languages": [
        "de"
      ],
      "recommendedHardware": {
        "cpu": "12-core",
        "gpu": "NVIDIA RTX 3060",
        "ramGb": 24,
        "vramGb": 12
      },
      "parameters": "7B",
      "sizeGb": 4.2,
      "rating": 4.2,
      "license": "MIT",
      "description": "Deutsches EM German 7B Q5 für natürliche Konversationen.",
      "tags": [
        "tier-2",
        "deutsch"
      ],
      "quantization": "Q5",
      "contextLength": 8192,
      "updatedAt": "2024-10-01"
    },
    {
      "id": "zephyr-7b-beta-q5",
      "name": "Zephyr 7B Beta Q5",
      "categories": [
        "chat",
        "quality"
      ],
      "checksum": "sha256:287504df85c30ea5bebcbd05286e2f7dfd968ebf3aa91fd5da90827cf659f8fd",
      "downloadUrl": "https://huggingface.co/TheBloke/zephyr-7B-beta-GGUF/resolve/main/zephyr-7b-beta.Q5_K_M.gguf",
      "languages": [
        "en"
      ],
      "recommendedHardware": {
        "cpu": "12-core",
        "gpu": "NVIDIA RTX 3060",
        "ramGb": 24,
        "vramGb": 12
      },
      "parameters": "7B",
      "sizeGb": 4.3,
      "rating": 4.3,
      "license": "Apache-2.0",
      "description": "Zephyr 7B Beta Q5 mit starker Chat-Qualität.",
      "tags": [
        "tier-2",
        "chat"
      ],
      "quantization": "Q5",
      "contextLength": 8192,
      "updatedAt": "2024-10-01"
    },
    {
      "id": "qwen-2.5-14b-q5",
      "name": "Qwen 2.5 14B Q5",
      "categories": [
        "multilingual",
        "advanced"
      ],
      "checksum": "sha256:fd9ff5dc4878378e3ef9c63dfdbaef3abda1ca8acad14d1f439432df4a1f17bd",
      "downloadUrl": "https://huggingface.co/bartowski/Qwen2.5-14B-Instruct-GGUF/resolve/main/Qwen2.5-14B-Instruct-Q5_K_M.gguf",
      "languages": [
        "en",
        "zh",
        "de",
        "fr"
      ],
      "recommendedHardware": {
        "cpu": "16-core",
        "gpu": "NVIDIA RTX 4090",
        "ramGb": 64,
        "vramGb": 24
      },
      "parameters": "14B",
      "sizeGb": 8.5,
      "rating": 4.6,
      "license": "Apache-2.0",
      "description": "Fortgeschrittenes Qwen 2.5 14B Q5 für viele Sprachen.",
      "tags": [
        "tier-2",
        "multilingual"
      ],
      "quantization": "Q5",
      "contextLength": 8192,
      "updatedAt": "2024-10-01"
    },
    {
      "id": "aya-23-8b-q5",
      "name": "Aya 23 8B Q5",
      "categories": [
        "multilingual",
        "chat"
      ],
      "checksum": "sha256:365dea235ba61556e9f84ac6c8949e2b2acc860ad69ea167b070b8cf524179d4",
      "downloadUrl": "https://huggingface.co/bartowski/aya-23-8B-GGUF/resolve/main/aya-23-8B-Q5_K_M.gguf",
      "languages": [
        "en",
        "de",
        "fr",
        "es",
        "it",
        "pt",
        "ar",
        "ja"
      ],
      "recommendedHardware": {
        "cpu": "12-core",
        "gpu": "NVIDIA RTX 3060",
        "ramGb": 24,
        "vramGb": 12
      },
      "parameters": "8B",
      "sizeGb": 4.7,
      "rating": 4.4,
      "license": "Apache-2.0",
      "description": "Aya 23 8B Q5 für 23 Sprachen.",
      "tags": [
        "tier-2",
        "multilingual"
      ],
      "quantization": "Q5",
      "contextLength": 8192,
      "updatedAt": "2024-10-01"
    },
    {
      "id": "starcoder2-7b-q5",
      "name": "StarCoder2 7B Q5",
      "categories": [
        "code",
        "multilingual"
      ],
      "checksum": "sha256:1d7b58d9fe0836ed2c746ceff4335d21ff8ab55cee807cdf437f4baccfab60d9",
      "downloadUrl": "https://huggingface.co/second-state/StarCoder2-7B-GGUF/resolve/main/starcoder2-7b-Q5_K_M.gguf",
      "languages": [
        "en",
        "es",
        "fr",
        "de"
      ],
      "recommendedHardware": {
        "cpu": "12-core",
        "gpu": "NVIDIA RTX 3060",
        "ramGb": 24,
        "vramGb": 12
      },
      "parameters": "7B",
      "sizeGb": 4.2,
      "rating": 4.5,
      "license": "BigCode",
      "description": "StarCoder2 7B Q5 für Code in 80+ Sprachen.",
      "tags": [
        "tier-2",
        "code"
      ],
      "quantization": "Q5",
      "contextLength": 16384,
      "updatedAt": "2024-10-01"
    },
    {
      "id": "nous-hermes-2-mistral-q5",
      "name": "Nous Hermes 2 Mistral Q5",
      "categories": [
        "chat",
        "creative"
      ],
      "checksum": "sha256:b53c0e17e099a47de12d1e28ac37120411c41b19973e1c36e2803060ab7b181f",
      "downloadUrl": "https://huggingface.co/NousResearch/Nous-Hermes-2-Mistral-7B-DPO-GGUF/resolve/main/Nous-Hermes-2-Mistral-7B-DPO.Q5_K_M.gguf",
      "languages": [
        "en"
      ],
      "recommendedHardware": {
        "cpu": "12-core",
        "gpu": "NVIDIA RTX 3060",
        "ramGb": 24,
        "vramGb": 12
      },
      "parameters": "7B",
      "sizeGb": 4.4,
      "rating": 4.3,
      "license": "MIT",
      "description": "Kreatives Nous Hermes 2 Mistral Q5.",
      "tags": [
        "tier-2",
        "creative"
      ],
      "quantization": "Q5",
      "contextLength": 8192,
      "updatedAt": "2024-10-01"
    }
  ]
}
