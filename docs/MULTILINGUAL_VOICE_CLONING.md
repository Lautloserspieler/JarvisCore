# Multilingual Voice Cloning fÃ¼r XTTS v2

**Version:** 1.0  
**Datum:** 2025-12-20  
**Status:** âœ… Productive

## Ãœbersicht

Das erweiterte TTS-System unterstÃ¼tzt nun **mehrsprachiges Voice Cloning mit intelligenter Caching-Mechanik**:

- ðŸ‡©ðŸ‡ª **Deutsch** - Automatisch erkannt und gecacht
- ðŸ‡¬ðŸ‡§ **Englisch** - Automatisch erkannt und gecacht  
- âš¡ **Performance** - Voice Clone Computation nur 1x pro Sprache (~2s), dann <10ms Latenz
- ðŸ”„ **Auto-Detection** - Sprache wird automatisch aus Text erkannt
- ðŸ’¾ **Persistent Caching** - Latents werden auf Disk gespeichert

## Konfiguration

### Minimale Konfiguration (Single-Language Legacy)

```yaml
speech:
  tts_backend: 'xtts'        # Oder pyttsx3 fÃ¼r Fallback
  tts_rate: 180              # Sprechgeschwindigkeit
  tts_volume: 0.8            # LautstÃ¤rke
  tts_use_gpu: true          # GPU-Beschleunigung
  voice_sample: 'models/tts/voices/Jarvis.wav'  # Wird fÃ¼r beide Sprachen verwendet
```

**Verhalten:** Wenn nur `voice_sample` gesetzt ist, wird die gleiche Stimme fÃ¼r Deutsch und Englisch verwendet.

### Empfohlene Konfiguration (Multilingual)

```yaml
speech:
  tts_backend: 'xtts'
  tts_rate: 180
  tts_volume: 0.8
  tts_use_gpu: true
  
  # Sprachspezifische Voice Samples
  voice_sample_de: 'models/tts/voices/Jarvis_DE.wav'    # Deutsch (z.B. mÃ¤nnlich)
  voice_sample_en: 'models/tts/voices/Jarvis_EN.wav'    # Englisch (z.B. amerikanisch)
  
  # Optional: Fallback wenn sprachspezifisches Sample nicht existiert
  voice_sample: 'models/tts/voices/Jarvis.wav'
  
  # Optional: Sprecher fÃ¼r Multi-Speaker-Modelle
  tts_xtts_speaker: 'speaker_0'
  
  # Optional: Preset fÃ¼r Voice Effects
  voice_preset: 'jarvis_marvel'  # Aktiviert Marvel-JARVIS-Effekte

models:
  tts:
    xtts:
      default_speaker: 'speaker_0'  # Fallback Speaker
```

## Voice Samples vorbereiten

### Audio-Anforderungen

```
Format:       WAV oder MP3
Sample-Rate:  22050 Hz oder hÃ¶her (empfohlen: 24000 Hz)
KanÃ¤le:       Mono oder Stereo
Dauer:        5-15 Sekunden (optimal: 10 Sekunden)
QualitÃ¤t:     Laut und deutlich, minimale HintergrundgerÃ¤usche
Inhalt:       Neutrale Sprachproben (z.B. "This is a voice sample for text-to-speech synthesis")
```

### Sample-Erstellung

**Deutsch (Jarvis_DE.wav):**
```
"Hallo, das ist eine Sprachabtastung fÃ¼r die Textsynthese. 
Jarvis ist ein intelligenter persÃ¶nlicher Assistent.
Ich kann mehrere Sprachen sprechen."
```

**Englisch (Jarvis_EN.wav):**
```
"Hello, this is a voice sample for text-to-speech synthesis.
I am Jarvis, an intelligent personal assistant.
I can speak multiple languages."
```

### Verzeichnisstruktur

```
JarvisCore/
â”œâ”€â”€ models/
â”‚   â””â”€â”€ tts/
â”‚       â””â”€â”€ voices/
â”‚           â”œâ”€â”€ Jarvis.wav          # Legacy/Fallback
â”‚           â”œâ”€â”€ Jarvis_DE.wav       # ðŸ‡©ðŸ‡ª Deutsch
â”‚           â””â”€â”€ Jarvis_EN.wav       # ðŸ‡¬ðŸ‡§ Englisch
â””â”€â”€ data/
    â””â”€â”€ tts/
        â”œâ”€â”€ voice_latents_de.pt     # Auto-generiert (Deutsch)
        â””â”€â”€ voice_latents_en.pt     # Auto-generiert (Englisch)
```

## Funktionsweise

### 1. Voice Clone Computation (Erste Verwendung pro Sprache)

```
Benutzer: "Hallo, wie geht es dir?"
         â†“
    [Language Detection] â†’ German (de)
         â†“
    [Check Latents Cache] â†’ voice_latents_de.pt existiert nicht
         â†“
    [Load Voice Sample] â†’ Jarvis_DE.wav
         â†“
    [Compute Latents] â†’ ~2 Sekunden â±ï¸
         â†“
    [Cache to Disk] â†’ voice_latents_de.pt
         â†“
    [Synthesize] â†’ Audio output
         â†“
    [Play] â†’ ðŸ”Š
```

**Dauer:** ~2-3 Sekunden (einmalig pro Sprache)

### 2. Voice Clone Usage (Nachfolgende Aufrufe)

```
Benutzer: "Wie ist das Wetter?"
         â†“
    [Language Detection] â†’ German (de)
         â†“
    [Check Latents Cache] â†’ voice_latents_de.pt existiert âœ“
         â†“
    [Load Cached Latents] â†’ <10ms âš¡
         â†“
    [Synthesize] â†’ Audio output
         â†“
    [Play] â†’ ðŸ”Š
```

**Dauer:** ~0.5-1 Sekunde (nur Synthese, kein Voice Cloning nÃ¶tig)

### 3. Sprachenwechsel

```
Benutzer: "Hallo!"
         â†“
    [Synthese mit German Latents]
         â†“

Benutzer: "Hello there!"
         â†“
    [Language Detection] â†’ English (en)
         â†“
    [Latents Ã¤ndern] â†’ voice_latents_en.pt
         â†“
    [Synthese mit English Latents]
```

**Wichtig:** Der XTTS-Modell selbst wird **nicht neu geladen**. Nur die Latents (Stimmprofil) wechseln.

## API-Verwendung

### Einfache Verwendung (Auto-Language Detection)

```python
from core.text_to_speech import TextToSpeech

tts = TextToSpeech(settings)

# Sprache wird automatisch erkannt
tts.speak("Hallo, wie geht es dir?")   # â†’ German
tts.speak("Hello, how are you?")       # â†’ English
```

### Explizite Sprachanforderung

```python
# Erzwinge Deutsch
tts.speak("Hello!", language='de')

# Erzwinge Englisch
tts.speak("Hallo!", language='en')

# Mit Style-Modifier
tts.speak("Guten Morgen!", language='de', style='freundlich')
```

### Mit Styles kombiniert

```python
# Deutsch + Stil
tts.speak("Das ist fantastisch!", language='de', style='humorvoll')

# Englisch + Stil
tts.speak("That is amazing!", language='en', style='professionell')
```

## Cache-Verwaltung

### Auto-Generated Caches

```
data/tts/
â”œâ”€â”€ voice_latents_de.pt    # Deutsch Voice Latents + Metadata
â”œâ”€â”€ voice_latents_en.pt    # Englisch Voice Latents + Metadata
â””â”€â”€ ...
```

### Cache-Inhalt

```python
# Jede .pt Datei enthÃ¤lt:
{
    "gpt_cond_latent": <torch.Tensor>,           # GPT-Konditionierung
    "speaker_embedding": <torch.Tensor>,         # Speaker-Embedding
    "sample_path": "/absolute/path/to/sample.wav",  # Referenz
    "sample_mtime": 1702958567.123,              # Ã„nderungsdatum
    "created": 1702958569.456,                   # Erstellungsdatum
    "language": "de"                             # Sprache
}
```

### Cache invalidieren (Manuell)

```bash
# Cache lÃ¶schen (wird beim nÃ¤chsten Start neu generiert)
rm data/tts/voice_latents_de.pt
rm data/tts/voice_latents_en.pt

# Oder Ã¼ber Python
import shutil
shutil.rmtree('data/tts')
```

### Cache auto-invalidieren bei Voice Sample Ã„nderung

Wenn `Jarvis_DE.wav` modifiziert wird:
1. `sample_mtime` wird bei Laden geprÃ¼ft
2. Falls unterschiedlich â†’ Cache wird verworfen
3. Neue Latents werden berechnet

## Performance-Charakteristiken

### Erste Initialisierung

```
Zustand: XTTS-Modell wird geladen + beide Voice Clones werden berechnet

Zeitlinie:
- XTTS-Modell laden: ~5-10s
- German Voice Clone: ~2s
- English Voice Clone: ~2s (parallel mÃ¶glich)
- Gesamt: ~10-15s

Speicher:
- XTTS Modell: ~3-4 GB (GPU) / ~6-8 GB (CPU)
- Voice Latents: ~100 KB je Sprache
```

### Laufzeit Pro Anfrage

| Szenario | Zeit | Notes |
|----------|------|-------|
| **First German call** | ~2-3s | Voice Clone + Synthesis |
| **German (cached)** | ~0.5-1s | Nur Synthesis |
| **English (cached)** | ~0.5-1s | Nur Synthesis |
| **Language switch** | <10ms | Nur Latents-Wechsel |
| **50 char text (DE)** | ~0.5s | Synthesis time |
| **250 char text (EN)** | ~1.5s | Synthesis time |

### Speicher-Footprint

```
After Init + Both Languages Cached:

Component               Size        Location
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
XTTS Modell             3-4 GB      GPU/RAM
German Latents          ~50 KB      disk (voice_latents_de.pt)
English Latents         ~50 KB      disk (voice_latents_en.pt)
Audio Output Cache      ~5-20 MB    output/tts_cache/ (24 files)
```

## Troubleshooting

### Problem: "Voice sample not found"

**Symptom:** `WARNING: XTTS hat kein Voice-Sample gefunden`

**LÃ¶sung:**
```yaml
# ÃœberprÃ¼fe die Config
speech:
  voice_sample_de: '/absolute/path/to/Jarvis_DE.wav'  # Absolute Pfade bevorzugt
  voice_sample_en: 'models/tts/voices/Jarvis_EN.wav'
  voice_sample: 'models/tts/voices/Jarvis.wav'        # Fallback
```

### Problem: "Language detection fails"

**Symptom:** Text wird in falscher Sprache synthesiert

**LÃ¶sung:**
```python
# Explizite Sprache angeben
tts.speak("Mein Name ist Jarvis", language='de')  # Erzwinge Deutsch
```

### Problem: Cache wird nicht verwendet

**Symptom:** Jede Anfrage dauert ~2s (Voice Clone statt cached)

**LÃ¶sung 1:** Cache-Ordner Ã¼berprÃ¼fen
```bash
ls -la data/tts/
# Sollte zeigen:
# voice_latents_de.pt
# voice_latents_en.pt
```

**LÃ¶sung 2:** Logs Ã¼berprÃ¼fen
```
grep "aus Cache geladen" logs/jarvis.log
# Sollte zeigen: "XTTS Voice-Latents fÃ¼r de aus Cache geladen."
```

### Problem: Voice klingt unterschiedlich je Sprache

**Erwartet:** Das ist normal! Unterschiedliche Voice Samples erzeugen unterschiedliche Klangfarben.

**Tipp:** Verwende identische Voice Samples fÃ¼r beide Sprachen wenn konsistente Stimme gewÃ¼nscht ist.

## Migration von Single-Language Setup

### Schritt 1: Alte Config sichern
```bash
cp config.yaml config.yaml.backup
```

### Schritt 2: Neue Voice Samples vorbereiten
```
models/tts/voices/
â”œâ”€â”€ Jarvis.wav          # â† Alte Config (bleibt erhalten!)
â”œâ”€â”€ Jarvis_DE.wav       # â† Neu: Deutsch
â””â”€â”€ Jarvis_EN.wav       # â† Neu: Englisch
```

### Schritt 3: Config erweitern
```yaml
# ALT (funktioniert noch):
speech:
  tts_backend: 'xtts'
  voice_sample: 'models/tts/voices/Jarvis.wav'

# NEU (empfohlen):
speech:
  tts_backend: 'xtts'
  voice_sample_de: 'models/tts/voices/Jarvis_DE.wav'
  voice_sample_en: 'models/tts/voices/Jarvis_EN.wav'
  voice_sample: 'models/tts/voices/Jarvis.wav'  # Fallback
```

### Schritt 4: Cache regenerieren
```bash
# Alt-Cache lÃ¶schen (optional)
rm -f data/tts/xtts_voice_latents.pt  # Legacy

# Neu-Cache wird beim Start auto-generiert
python main.py
```

**Ergebnis:** Beim ersten Start werden automatisch `voice_latents_de.pt` und `voice_latents_en.pt` generiert.

## Best Practices

### 1. Voice Samples auf QualitÃ¤t Ã¼berprÃ¼fen

```bash
# Mit ffprobe (wenn installiert)
ffprobe -v error -select_streams a:0 -show_entries stream=codec_name,sample_rate,channels -of default=noprint_wrappers=1:nokey=1:noprivate=1 Jarvis_DE.wav

# Erwartet: codec=pcm_s16le oder Ã¤hnlich, sample_rate=22050+, channels=1 oder 2
```

### 2. Separate Stimmen fÃ¼r jede Sprache

```yaml
# Gut: Unterschiedliche Sprecher/Akzente
voice_sample_de: 'models/tts/voices/Jarvis_DE_male.wav'  # Deutsch, mÃ¤nnlich
voice_sample_en: 'models/tts/voices/Jarvis_EN_female.wav'  # Englisch, weiblich

# Auch gut: Gleiche Person, aber in jeder Sprache
voice_sample_de: 'models/tts/voices/same_person_de.wav'
voice_sample_en: 'models/tts/voices/same_person_en.wav'

# Nicht empfohlen: Gleiches Sample fÃ¼r beide
voice_sample: 'models/tts/voices/one_sample.wav'  # Akzent bei nicht-Muttersprache
```

### 3. Logs Ã¼berwachen

```bash
# Cache-Generierung Ã¼berprÃ¼fen
grep -E "Computing voice latents|aus Cache geladen" logs/jarvis.log

# Performance Ã¼berprÃ¼fen
grep -E "XTTS queued|Sprachausgabe gestoppt" logs/jarvis.log
```

### 4. Voice Latents regelmÃ¤ÃŸig Ã¼berprÃ¼fen

```python
# In einem Monitoring-Script
import os
from pathlib import Path

for lang in ['de', 'en']:
    cache = Path('data/tts') / f'voice_latents_{lang}.pt'
    if cache.exists():
        size = cache.stat().st_size
        print(f"{lang}: {size} bytes, exists: âœ“")
    else:
        print(f"{lang}: missing (will be regenerated on first use)")
```

## Zu den technischen Details

### Warum Latents Caching?

Die Voice Cloning Berechnung ist der teuerste Schritt:
```
1. Audio laden (schnell)
2. Mel-Spectrogram erstellen (schnell)
3. GPT-Model durchlaufen (~1.5s) â† GPU/CPU-intensive Berechnung
4. Sprecher-Embedding extrahieren (~0.5s) â† GPU/CPU-intensive Berechnung
5. Tensor serialisieren (schnell)
```

Durch Caching sparen wir Schritte 3-4 (~2s) fÃ¼r alle nachfolgenden Anfragen.

### Warum separate Caches pro Sprache?

- **Modell-Konsistenz:** Ein XTTS-Modell pro Sprache kÃ¶nnte verschieden sein
- **Voice-Varianz:** Unterschiedliche Voice Samples erzeugen unterschiedliche Embeddings
- **Klang-Optimierung:** Jede Sprache kann eigene Stimm-Charakteristiken haben
- **Wartbarkeit:** Einfacher zu debuggen und zu verstehen

### Warum Auto-Language Detection?

- **UX:** Benutzer mÃ¼ssen Sprache nicht manuell angeben
- **Konsistenz:** Richtige Phoneme und Prosodie pro Sprache
- **Fallback:** Python-Heuristik falls Erkennung unsicher

## Siehe auch

- [XTTS v2 Dokumentation](https://github.com/coqui-ai/TTS)
- [Konfiguration](./CONFIG.md)
- [Audio-Setup](./AUDIO_SETUP.md)
