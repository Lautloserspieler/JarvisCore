# ğŸš€ Enhanced Model Manager - Documentation

**Version:** 1.0.0  
**Last Updated:** December 10, 2025

---

## ğŸ“‹ Overview

Der Enhanced Model Manager erweitert die bestehende LLM-Verwaltung in JarvisCore um:

- âœ… **Download-Progress-Tracking** mit Echtzeit-Fortschrittsanzeige
- âœ… **Automatisches Benchmarking** fÃ¼r Performance-Metriken
- âœ… **Model-Comparison-View** zum Vergleich mehrerer Modelle
- âœ… **Context-Window-Visualisierung** fÃ¼r Token-Nutzung
- âœ… **Persistente Benchmark-Ergebnisse** mit History
- âœ… **Detaillierte Modell-Informationen** (GPU-Layer, Ladezeit, Speicher)

---

## ğŸ¯ Features im Detail

### 1. Download Progress Tracking

**FunktionalitÃ¤t:**
- Echtzeit-Download-Progress mit Geschwindigkeit und ETA
- Visueller Progress-Bar mit Prozentanzeige
- Heruntergeladene/Gesamt-Bytes-Anzeige
- Automatisches Refresh nach erfolgreichem Download
- Error-Handling mit detaillierten Fehlermeldungen

**UI-Elemente:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Downloading MISTRAL                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Status: Downloading...              â”‚
â”‚ [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 65.3%        â”‚
â”‚                                     â”‚
â”‚ Downloaded: 2.7 GB / 4.1 GB         â”‚
â”‚ Speed: 15.3 MB/s     ETA: 1m 32s    â”‚
â”‚                                     â”‚
â”‚ [Close (disabled)]                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Implementierung:**
- `ModelDownloadManager` verwaltet Downloads
- Callback-System fÃ¼r UI-Updates
- Thread-sichere Progress-Speicherung
- Automatische Geschwindigkeits- und ETA-Berechnung

---

### 2. Model Benchmarking

**FunktionalitÃ¤t:**
- Automatische Performance-Tests mit standardisiertem Prompt
- Messung von Tokens/Sekunde, Inference-Zeit, Memory-Usage
- Persistente Speicherung in `data/model_benchmarks.json`
- History der letzten 10 Benchmark-Runs pro Modell
- Durchschnitts-Performance-Berechnung

**Gemessene Metriken:**
- **Tokens/Second**: Durchsatz (hÃ¶her = besser)
- **Inference Time**: Antwortzeit in Millisekunden (niedriger = besser)
- **Memory Usage**: RAM-Verbrauch in MB
- **Context Usage**: Genutzte vs. verfÃ¼gbare Tokens
- **Prompt/Completion Tokens**: Token-Verteilung

**Benchmark-Prompt:**
```python
test_prompt = (
    "Explain quantum computing in simple terms. "
    "Focus on the key principles and practical applications."
)
```

**Ergebnis-Format:**
```json
{
  "model_key": "mistral",
  "tokens_per_second": 45.32,
  "inference_time": 3250.5,
  "context_used": 158,
  "context_available": 8192,
  "timestamp": "2025-12-10T19:30:45.123456",
  "prompt_tokens": 25,
  "completion_tokens": 133,
  "memory_usage_mb": 4829.3
}
```

---

### 3. Model Comparison

**FunktionalitÃ¤t:**
- Side-by-Side-Vergleich mehrerer Modelle
- Sortierung nach Performance-Metriken
- Automatische Identifikation des schnellsten/effizientesten Modells
- Tabellarische Darstellung mit Highlighting

**Vergleichs-Tabelle:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ“Š Performance Comparison                                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Model   â”‚ Tokens/Sec â”‚ Inference(ms)â”‚ Memory(MB) â”‚ Context     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ MISTRAL â”‚ 45.32      â”‚ 3250.5       â”‚ 4829.3     â”‚ 158/8192    â”‚
â”‚ LLAMA3  â”‚ 38.17      â”‚ 3890.2       â”‚ 5123.7     â”‚ 165/8192    â”‚
â”‚ DEEPSEEKâ”‚ 28.44      â”‚ 5210.8       â”‚ 6890.1     â”‚ 172/8192    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ† Fastest: MISTRAL (45.32 tokens/sec)
ğŸ’¾ Most Efficient: MISTRAL (4829.3 MB)
```

---

### 4. Context Window Visualization

**FunktionalitÃ¤t:**
- Farbcodierte Progress-Bar fÃ¼r Token-Nutzung
- GrÃ¼n (< 50%), Orange (50-80%), Rot (> 80%)
- Numerische Anzeige: `Used/Available tokens`
- Integration in Benchmark-Ergebnisse

**Visualisierung:**
```
Context: 158/8192 tokens [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 1.9%
```

---

### 5. Enhanced Model List

**Erweiterte Informationen pro Modell:**
- âœ…/âŒ Ready-Status
- ğŸŸ¢ Active-Indicator
- ğŸ”µ Loaded-Indicator
- ğŸ“ Display Name und Description
- ğŸ“ Dateiname und GrÃ¶ÃŸe
- ğŸ“Š Context Window Size
- âš¡ Latest/Average Benchmark Results
- ğŸ® GPU-Layer-Info
- â±ï¸ Load Time

**Beispiel-Ausgabe:**
```
âœ…  MISTRAL  ğŸŸ¢ ACTIVE  ğŸ”µ LOADED
     ğŸ“ Nous Hermes 2 (Mistral 7B DPO)
     ğŸ’¬ Einsatzgebiet: Code, technische Details, Systembefehle
     ğŸ“ Nous-Hermes-2-Mistral-7B-DPO.Q4_K_M.gguf (4.1 GB)
     ğŸ“Š Context Window: 8192 tokens
     âš¡ Latest Benchmark:
        â€¢ 45.3 tokens/sec
        â€¢ 3251 ms inference time
        â€¢ 4829.3 MB memory
     ğŸ® GPU Acceleration: 35 layers
     â±ï¸  Load Time: 8.3s
```

---

## ğŸ“¦ Installation

### Voraussetzungen

```bash
# Bereits in requirements.txt enthalten:
pip install dearpygui psutil requests
```

### Integration

**Option 1: VollstÃ¤ndige Integration (Empfohlen)**

Ersetze den Model-Manager-Tab in `desktop/jarvis_imgui_app_full.py`:

```python
# Am Anfang der Datei importieren
from desktop.model_manager_ui import ExtendedModelManagerUI

# In der __init__-Methode initialisieren
self.model_manager_ui = ExtendedModelManagerUI(jarvis_instance)

# Im _build_ui Tab erstellen
with dpg.tab(label="  ğŸ§  Models  "):
    self.model_manager_ui.build_ui(dpg.last_container())
```

**Option 2: Standalone-Nutzung**

Verwende die Klassen direkt:

```python
from desktop.model_manager_extended import ModelBenchmark, ModelDownloadManager

# Benchmarking
benchmark = ModelBenchmark(jarvis_instance)
result = benchmark.run_benchmark("mistral")
print(f"Performance: {result.tokens_per_second:.2f} tokens/sec")

# Download mit Progress
download_manager = ModelDownloadManager(jarvis_instance)
download_manager.register_callback(lambda p: print(f"Progress: {p.percent}%"))
download_manager.download_model("llama3")
```

---

## ğŸ”§ API-Referenz

### ModelBenchmark

```python
class ModelBenchmark:
    def __init__(self, jarvis_instance)
    def run_benchmark(self, model_key: str, progress_callback: Optional[Callable] = None) -> Optional[BenchmarkResult]
    def get_latest_result(self, model_key: str) -> Optional[BenchmarkResult]
    def get_average_performance(self, model_key: str) -> Optional[Dict[str, float]]
```

**Beispiel:**
```python
benchmark = ModelBenchmark(jarvis)

# Run benchmark
result = benchmark.run_benchmark(
    "mistral",
    progress_callback=lambda data: print(data['status'])
)

if result:
    print(f"Tokens/sec: {result.tokens_per_second}")
    print(f"Inference: {result.inference_time} ms")
    print(f"Memory: {result.memory_usage_mb} MB")

# Get historical data
avg = benchmark.get_average_performance("mistral")
print(f"Average: {avg['avg_tokens_per_second']} tokens/sec")
```

---

### ModelDownloadManager

```python
class ModelDownloadManager:
    def __init__(self, jarvis_instance)
    def register_callback(self, callback: Callable)
    def download_model(self, model_key: str) -> bool
    def get_progress(self, model_key: str) -> Optional[DownloadProgress]
    def is_downloading(self, model_key: str) -> bool
```

**Beispiel:**
```python
download_manager = ModelDownloadManager(jarvis)

# Register callback for progress updates
def on_progress(progress: DownloadProgress):
    print(f"Status: {progress.status}")
    print(f"Progress: {progress.percent}%")
    print(f"Speed: {format_speed(progress.speed)}")
    print(f"ETA: {format_eta(progress.eta)}")

download_manager.register_callback(on_progress)

# Start download
success = download_manager.download_model("llama3")
if success:
    print("Download completed!")
```

---

### ContextWindowVisualizer

```python
class ContextWindowVisualizer:
    @staticmethod
    def create_visualization(context_used: int, context_available: int, parent_tag: str)
```

**Beispiel:**
```python
ContextWindowVisualizer.create_visualization(
    context_used=158,
    context_available=8192,
    parent_tag="my_window"
)
```

---

### ExtendedModelManagerUI

```python
class ExtendedModelManagerUI:
    def __init__(self, jarvis_instance)
    def build_ui(self, parent_tag: str)
```

**Beispiel:**
```python
model_ui = ExtendedModelManagerUI(jarvis)

# In DearPyGui window/tab
with dpg.window(label="Models"):
    model_ui.build_ui(dpg.last_container())
```

---

## ğŸ“Š Datenformate

### DownloadProgress

```python
@dataclass
class DownloadProgress:
    model: str                      # Model key (e.g., "mistral")
    status: str                     # "in_progress", "completed", "failed", "error"
    downloaded: int                 # Bytes downloaded
    total: int                      # Total bytes
    percent: Optional[float]        # Progress percentage (0-100)
    speed: Optional[float]          # Download speed (bytes/sec)
    eta: Optional[float]            # Estimated time remaining (seconds)
    message: Optional[str]          # Optional status message
```

---

### BenchmarkResult

```python
@dataclass
class BenchmarkResult:
    model_key: str                  # Model identifier
    tokens_per_second: float        # Throughput
    inference_time: float           # Time in milliseconds
    context_used: int               # Tokens used in benchmark
    context_available: int          # Max context window size
    timestamp: datetime             # When benchmark was run
    prompt_tokens: int              # Input tokens
    completion_tokens: int          # Output tokens
    memory_usage_mb: float          # RAM usage
```

---

### Benchmark Storage Format

**Datei:** `data/model_benchmarks.json`

```json
{
  "mistral": [
    {
      "model_key": "mistral",
      "tokens_per_second": 45.32,
      "inference_time": 3250.5,
      "context_used": 158,
      "context_available": 8192,
      "timestamp": "2025-12-10T19:30:45.123456",
      "prompt_tokens": 25,
      "completion_tokens": 133,
      "memory_usage_mb": 4829.3
    }
  ],
  "llama3": [...],
  "deepseek": [...]
}
```

---

## ğŸ¨ UI-Komponenten

### Action Buttons

```python
[ğŸ”„ Refresh] [ğŸ“¥ Download] [âš¡ Benchmark] [ğŸ” Compare] [ğŸ”´ Unload All]
```

- **Refresh**: Aktualisiert Modellliste mit aktuellen Informationen
- **Download**: Ã–ffnet Download-Dialog fÃ¼r verfÃ¼gbare Modelle
- **Benchmark**: Startet Performance-Test fÃ¼r geladene Modelle
- **Compare**: Zeigt Vergleichstabelle fÃ¼r gebenchmarkte Modelle
- **Unload All**: EntlÃ¤dt alle aktuell geladenen Modelle

---

### Download Dialog

**Features:**
- Liste aller nicht-heruntergeladenen Modelle
- Anzeige von Name, Beschreibung, GrÃ¶ÃŸe, Context-Length
- Download-Button pro Modell
- Automatisches SchlieÃŸen nach Auswahl

---

### Progress Window

**Features:**
- Echtzeit-Progress-Bar mit Prozentanzeige
- Heruntergeladene/Gesamt-Bytes
- Download-Geschwindigkeit (MB/s)
- ETA (Estimated Time Arrival)
- Status-Text mit Fehlermeldungen
- Deaktivierter Close-Button wÃ¤hrend Download

---

### Benchmark Dialog

**Features:**
- Liste aller verfÃ¼gbaren Modelle
- Kennzeichnung bereits geladener Modelle
- Einzeln- oder Alle-Benchmarking
- Automatisches Laden falls nÃ¶tig

---

### Comparison View

**Features:**
- Sortierbare Tabelle mit allen Metriken
- Highlighting des schnellsten Modells (ğŸ†)
- Highlighting des effizientesten Modells (ğŸ’¾)
- Farbcodierte Performance-Indikatoren

---

## ğŸ” Troubleshooting

### Problem: Benchmark schlÃ¤gt fehl

**Ursache:** Modell nicht geladen oder llama_cpp nicht verfÃ¼gbar

**LÃ¶sung:**
```python
# PrÃ¼fe ob Modell bereit ist
if jarvis.llm_manager.is_model_ready("mistral"):
    jarvis.llm_manager.load_model("mistral")
    benchmark.run_benchmark("mistral")
```

---

### Problem: Download hÃ¤ngt

**Ursache:** Netzwerkprobleme oder falsche URL

**LÃ¶sung:**
```python
# PrÃ¼fe Download-Status
progress = download_manager.get_progress("mistral")
if progress.status == "error":
    print(f"Error: {progress.message}")

# Retry download
download_manager.download_model("mistral")
```

---

### Problem: Benchmarks werden nicht gespeichert

**Ursache:** Keine Schreibrechte fÃ¼r `data/` Verzeichnis

**LÃ¶sung:**
```bash
mkdir -p data
chmod 755 data
```

---

## ğŸš€ Performance-Tipps

### GPU-Beschleunigung

```bash
# Aktiviere GPU fÃ¼r schnellere Benchmarks
export LLAMA_USE_GPU=1
export LLAMA_GPU_LAYERS=-1  # Alle Layer auf GPU
```

### Cache-Management

```python
# Disable cache for accurate benchmarks
result = llm_manager.generate_response(
    prompt=test_prompt,
    enable_cache=False  # Wichtig fÃ¼r Benchmarking!
)
```

### Benchmark-Frequenz

- **Empfehlung:** 1x pro Woche oder nach Modell-Updates
- **Nicht empfohlen:** Nach jedem Load (zu zeitintensiv)

---

## ğŸ“ Changelog

### Version 1.0.0 (2025-12-10)

**Features:**
- âœ… Initial Release
- âœ… Download Progress Tracking
- âœ… Model Benchmarking
- âœ… Model Comparison
- âœ… Context Window Visualization
- âœ… Persistent Benchmark Storage
- âœ… Enhanced Model List

---

## ğŸ¤ Contributing

VerbesserungsvorschlÃ¤ge willkommen!

**Geplante Features:**
- [ ] Live-Context-Monitoring wÃ¤hrend Inferenz
- [ ] Export von Benchmark-Ergebnissen als CSV
- [ ] Automatische Benchmark-Scheduling
- [ ] Model-Performance-History-Charts
- [ ] GPU-Memory-Monitoring

---

## ğŸ“„ Lizenz

Apache 2.0 - Siehe [LICENSE](../LICENSE)

---

## ğŸ“§ Support

- **Issues:** [GitHub Issues](https://github.com/Lautloserspieler/JarvisCore/issues)
- **Discussions:** [GitHub Discussions](https://github.com/Lautloserspieler/JarvisCore/discussions)
- **Email:** emeyer@fn.de
