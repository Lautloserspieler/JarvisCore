# ğŸ¤– J.A.R.V.I.S. Core - Desktop Edition

> **Just A Rather Very Intelligent System** - Native Desktop AI Assistant with Advanced Capabilities

[![License](https://img.shields.io/badge/License-Proprietary-red.svg)](LICENSE)
[![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)](https://python.org)
[![Go](https://img.shields.io/badge/Go-1.21+-00ADD8.svg)](https://golang.org)
[![Wails](https://img.shields.io/badge/Wails-v2-673ab8.svg)](https://wails.io)
[![Vue](https://img.shields.io/badge/Vue-3.0-42b883.svg)](https://vuejs.org)

---

## ğŸ“‹ **Inhaltsverzeichnis**

- [âœ¨ Features](#-features)
- [ğŸ—ï¸ Architektur](#-architektur)
- [ğŸ“¦ Installation](#-installation)
- [ğŸš€ Schnellstart](#-schnellstart)
- [ğŸ¨ Desktop UI](#-desktop-ui-features)
- [ğŸ“¡ Backend API](#-backend-api)
- [âš™ï¸ Konfiguration](#-konfiguration)
- [ğŸ› ï¸ Entwicklung](#-entwicklung)
- [ğŸ”„ Migration](#-migration-web--desktop)
- [ğŸ› Troubleshooting](#-troubleshooting)
- [ğŸ“Š Performance](#-performance)
- [ğŸ¯ Roadmap](#-roadmap)
- [âš–ï¸ Lizenz](#-lizenz)

---

## âœ¨ **Features**

### **ğŸ¯ Core Capabilities**

- **ğŸ§  Local LLM System**
  - 3 lokale Sprachmodelle von Hugging Face
  - **LLaMA 3 (8B)** - Conversation & Creative Tasks
  - **Mistral/Hermes (7B)** - Code & Technical Tasks
  - **DeepSeek R1 (8B)** - Analysis & Research
  - Automatischer Download Ã¼ber Model Manager UI
  - GGUF Format mit llama-cpp-python
  - GPU-Acceleration Support (CUDA)
  - Intelligente Modellwahl basierend auf Task-Type
  - **Komplett offline & kostenlos** (keine API Keys)

- **ğŸ“š Knowledge Base System**
  - Automatisches Web-Crawling & Indexierung
  - Vector-basierte Semantic Search (Sentence-BERT)
  - Real-time Knowledge Feed mit Progress-Tracking

- **ğŸ§  Advanced Memory System**
  - Langzeit-Memory mit Timeline-Visualisierung
  - Context-basiertes Memory-Retrieval
  - Semantic Search Ã¼ber Memory-EintrÃ¤ge

- **ğŸ“ Reinforcement Learning**
  - Adaptive Command Recognition
  - User-specific Pattern Learning
  - Top-Command Analytics & Optimization

- **ğŸ”Œ Plugin System**
  - Hot-loading von Custom Plugins
  - Enable/Disable ohne Neustart
  - Extensible Plugin API

- **ğŸ™ï¸ Voice Control**
  - Spracheingabe via Whisper (OpenAI)
  - Real-time Audio Visualizer
  - Hands-free Operation

- **ğŸ”’ Security Features**
  - Passphrase-based Authentication
  - TOTP 2FA Support (Google Authenticator)
  - Encrypted Memory Storage

---

## ğŸ—ï¸ **Architektur**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Desktop UI (Native App)                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Frontend: Vue 3 + TypeScript + Vite                  â”‚  â”‚
â”‚  â”‚  - 11 Responsive Views                                 â”‚  â”‚
â”‚  â”‚  - WebSocket Live-Updates                             â”‚  â”‚
â”‚  â”‚  - Voice Recording + Visualizer                       â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                        â”‚ Wails Bridge (IPC)                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Backend: Go + Wails v2                               â”‚  â”‚
â”‚  â”‚  - HTTP API Proxy (â†’ Python Backend)                  â”‚  â”‚
â”‚  â”‚  - WebSocket Manager                                   â”‚  â”‚
â”‚  â”‚  - Single Binary Compilation                          â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚ HTTP/WebSocket
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚   Python Backend (Core)     â”‚
          â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
          â”‚  â”‚ JarvisCore Engine      â”‚ â”‚
          â”‚  â”‚ - NLP Processing       â”‚ â”‚
          â”‚  â”‚ - Local LLM Manager    â”‚ â”‚
          â”‚  â”‚ - Knowledge Manager    â”‚ â”‚
          â”‚  â”‚ - Memory System        â”‚ â”‚
          â”‚  â”‚ - Plugin Orchestrator  â”‚ â”‚
          â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
          â”‚                              â”‚
          â”‚  HTTP API (Port 5050)        â”‚
          â”‚  WebSocket (Port 8765)       â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### **Tech Stack**

| Layer | Technologien |
|-------|-------------|
| **Frontend** | Vue 3, TypeScript, Vite, Axios, WebSocket API |
| **Desktop Bridge** | Go 1.21+, Wails v2, Gorilla WebSocket |
| **Backend** | Python 3.10+, asyncio, aiohttp, FastAPI |
| **AI/ML** | llama-cpp-python, Hugging Face Models (GGUF), Sentence-BERT |
| **Database** | JSON-based Storage (Memory, Knowledge, Training Data) |
| **Voice** | Whisper (OpenAI), Web Audio API |
| **Security** | bcrypt, pyotp (TOTP) |

---

## ğŸ“¦ **Installation**

### **Voraussetzungen**

#### **Python Backend**
```bash
# Python 3.10 oder hÃ¶her
python --version

# Empfohlen: Virtual Environment
python -m venv venv
source venv/bin/activate  # Linux/macOS
venv\Scripts\activate     # Windows
```

#### **Desktop UI (Go + Wails)**
```bash
# Go 1.21 oder hÃ¶her
go version

# Node.js 18+ (fÃ¼r Frontend)
node --version

# Wails CLI installieren
go install github.com/wailsapp/wails/v2/cmd/wails@latest
```

### **Installation Schritte**

```bash
# 1. Repository klonen
git clone https://github.com/Lautloserspieler/JarvisCore.git
cd JarvisCore

# 2. Python Dependencies
pip install -r requirements.txt

# 3. Desktop UI Dependencies (optional)
cd desktop/frontend
npm install
cd ../..

# 4. Konfiguration
cp config/settings.example.py config/settings.py
vim config/settings.py  # Einstellungen anpassen
```

---

## ğŸš€ **Schnellstart**

### **â­ Empfohlen: Unified Launcher (1 Befehl!)**

```bash
# ğŸš€ EINFACHSTE METHODE - Startet Backend + Desktop UI automatisch

# Windows:
start_jarvis.bat

# Linux/macOS:
chmod +x start_jarvis.sh
./start_jarvis.sh

# Oder direkt mit Python:
python start_jarvis.py

# Optionen:
python start_jarvis.py --dev      # Development Mode (Hot-Reload)
python start_jarvis.py --build    # Desktop Binary bauen
python start_jarvis.py --backend  # Nur Backend (kein UI)
```

**Das war's! ğŸ‰ Backend + Desktop UI starten automatisch.**

---

### **Alternative: Manueller Start (2 Terminals)**

#### **Terminal 1: Python Backend**
```bash
cd JarvisCore
python main.py

# Warte auf:
# âœ… API: http://127.0.0.1:5050
# âœ… WebSocket: ws://127.0.0.1:8765
```

#### **Terminal 2: Desktop UI**
```bash
cd desktop
make dev
# oder: wails dev

# âœ… App Ã¶ffnet automatisch
```

---

### **Production Build**

```bash
# Desktop Binary bauen
python start_jarvis.py --build

# Oder manuell:
cd desktop
make build

# Output:
# âœ… Windows: build/bin/jarvis-desktop.exe (~28MB)
# âœ… Linux:   build/bin/jarvis-desktop
# âœ… macOS:   build/bin/jarvis-desktop.app
```

**Deployment:**
```bash
# Backend muss laufen
python main.py &

# Binary starten
./desktop/build/bin/jarvis-desktop
```

---

## ğŸ¨ **Desktop UI Features**

### **11 Haupt-Ansichten**

| View | Icon | Features |
|------|------|----------|
| **Chat** | ğŸ’¬ | Text & Voice Input, Streaming, Visualizer |
| **System** | ğŸ“Š | CPU/RAM/GPU Monitoring, Live-Updates |
| **Models** | ğŸ§  | LLM Download, Load/Unload, 3 Models |
| **Plugins** | ğŸ”Œ | Enable/Disable, Configuration |
| **Knowledge** | ğŸ“š | Crawling Feed, Stats, Search |
| **Memory** | ğŸ§  | Timeline, Search, Export |
| **Logs** | ğŸ“‹ | Real-time Streaming, Filters |
| **Training** | ğŸ¯ | RL Stats, Top Commands |
| **Commands** | ğŸ® | Pattern Editor, Testing |
| **Settings** | âš™ï¸ | Audio, Config |
| **Security** | ğŸ”’ | Passphrase/TOTP Overlay (Global) |

---

## ğŸ“¡ **Backend API**

### **HTTP Endpoints**

```python
# System
GET  /api/status              # Backend Status
GET  /api/system/metrics      # CPU/RAM/GPU

# Chat
POST /api/command             # Send Message

# Models
GET  /api/models              # List Models (llama3, mistral, deepseek)
POST /api/models/load         # Load Model
POST /api/models/download     # Download Model from Hugging Face

# Knowledge
GET  /api/knowledge/stats     # KB Stats

# Memory
GET  /api/memory              # Memory Timeline
POST /api/memory/search       # Search

# Logs
GET  /api/logs                # Get Logs
POST /api/logs/clear          # Clear Logs

# Training
GET  /api/training            # RL Stats

# Commands
GET  /api/commands            # List Commands
POST /api/commands            # Add Command

# Plugins
GET  /api/plugins             # List Plugins
POST /api/plugins/toggle      # Enable/Disable
```

### **WebSocket Events**

```javascript
// Connect
ws://127.0.0.1:8765

// Events
- system_metrics      // Live CPU/RAM/GPU
- chat_message        // New Messages
- knowledge_progress  // Crawling Progress
- memory_update       // Memory Changes
- security_challenge  // 2FA Prompt
- log_entry           // New Log
- training_progress   // RL Updates
- model_download      // Model Download Progress
```

---

## âš™ï¸ **Konfiguration**

**config/settings.py:**

```python
# LLM Settings
DEFAULT_MODEL = "llama3"  # oder "mistral", "deepseek"
LLM_MAX_CACHED_MODELS = 2  # Wie viele Modelle im RAM halten
LLM_CPU_THREADS = 8        # CPU Threads fÃ¼r Inference
LLAMA_USE_GPU = 1          # GPU aktivieren (CUDA)
LLAMA_GPU_LAYERS = -1      # -1 = alle Layer auf GPU

# Backend
API_HOST = "127.0.0.1"
API_PORT = 5050
WEBSOCKET_PORT = 8765

# Security
SECURITY_PASSPHRASE = "your-passphrase"
TOTP_SECRET = "BASE32SECRET"

# Logging
LOG_LEVEL = "INFO"
```

---

## ğŸ› ï¸ **Entwicklung**

### **Projekt-Struktur**

```
JarvisCore/
â”œâ”€â”€ start_jarvis.py              # â­ Unified Launcher
â”œâ”€â”€ start_jarvis.bat             # Windows Launcher
â”œâ”€â”€ start_jarvis.sh              # Linux/macOS Launcher
â”œâ”€â”€ main.py                      # Backend Entry
â”œâ”€â”€ config/settings.py           # Configuration
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ llm_manager.py           # LLM Manager (3 Models)
â”‚   â”œâ”€â”€ llm_router.py            # Intelligente Modellwahl
â”‚   â””â”€â”€ ...
â”œâ”€â”€ models/llm/                  # LLM Download-Ordner
â”œâ”€â”€ plugins/                     # Plugin System
â”œâ”€â”€ data/                        # Storage
â””â”€â”€ desktop/                     # Desktop UI
    â”œâ”€â”€ main.go                  # Go Entry
    â”œâ”€â”€ frontend/                # Vue 3
    â”‚   â”œâ”€â”€ src/components/
    â”‚   â””â”€â”€ package.json
    â””â”€â”€ backend/internal/        # Go Bridge
```

### **Development Commands**

```bash
# Unified Launcher (empfohlen)
python start_jarvis.py --dev

# Oder manuell:
# Backend
python main.py

# Frontend (Standalone)
cd desktop/frontend && npm run dev

# Full Desktop (Wails)
cd desktop && make dev

# Production Build
python start_jarvis.py --build
```

---

## ğŸ”„ **Migration (Web UI â†’ Desktop)**

**Web UI wurde am 05.12.2025 entfernt!**

Siehe [MIGRATION.md](MIGRATION.md) fÃ¼r Details.

**Kurz:**
```bash
# ALT (Web UI)
python main.py  # â†’ Browser Ã¶ffnet auf :8080

# NEU (Desktop UI)
python start_jarvis.py  # â†’ Backend + Desktop starten automatisch
```

---

## ğŸ› **Troubleshooting**

### **"Backend startet nicht"**
```bash
pip install -r requirements.txt
lsof -ti:5050 | xargs kill -9  # Port freigeben (Linux/macOS)
netstat -ano | findstr :5050   # Port prÃ¼fen (Windows)
```

### **"Desktop UI startet nicht"**
```bash
# Wails installieren
go install github.com/wailsapp/wails/v2/cmd/wails@latest

# Frontend Dependencies
cd desktop/frontend && npm install

# Binary fehlt? Baue neu:
python start_jarvis.py --build
```

### **"LLM Modell lÃ¤dt nicht"**
```bash
# Modell herunterladen Ã¼ber UI: Models View â†’ Download Button
# Oder manuell von Hugging Face:
# https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct-GGUF
# Datei nach models/llm/ kopieren
```

### **"WebSocket Connection Failed"**
```bash
# Backend lÃ¤uft?
curl http://127.0.0.1:5050/api/status

# WebSocket Port frei?
netstat -an | grep 8765
```

---

## ğŸ“Š **Performance**

### **System Requirements**

| Komponente | Minimum | Empfohlen |
|------------|---------|------------|
| **CPU** | 4 Cores @ 2.5 GHz | 8 Cores @ 3.5 GHz |
| **RAM** | 8 GB | 16 GB |
| **GPU** | - | NVIDIA RTX 3060+ (fÃ¼r GPU-Acceleration) |
| **Disk** | 10 GB (+ 5-7GB pro LLM) | 50 GB |

### **Benchmarks**
```
Startup:         2-3s (Desktop) + 3-5s (Backend)
Memory:          120 MB (Desktop) + 400 MB (Backend)
Binary Size:     28 MB
LLM Inference:   ~50 tokens/s (CPU), ~200 tokens/s (GPU)
```

---

## ğŸ¯ **Roadmap**

### **v1.1 (Q1 2026)**
- [ ] System Tray Integration
- [ ] Global Hotkeys
- [ ] Multi-Language Support
- [ ] Mehr LLM Modelle (Qwen, Phi-3)

### **v1.2 (Q2 2026)**
- [ ] Wake Word Detection
- [ ] Screen Capture & Analysis
- [ ] Calendar Integration
- [ ] Smart Home Integration
- [ ] Cloud Sync

### **v2.0 (Q3 2026)**
- [ ] Distributed Architecture
- [ ] Browser Extension
- [ ] Plugin Marketplace
- [ ] Enterprise Features
- [ ] Cloud-LLM Option (OpenAI, Anthropic)

---

## âš–ï¸ **Lizenz**

**Proprietary License** - Â© 2025 Lautloserspieler

Dieses Projekt ist privat. Kommerzielle Nutzung nur nach Genehmigung.

---

## ğŸ“ **Support**

- **Issues:** [GitHub Issues](https://github.com/Lautloserspieler/JarvisCore/issues)
- **Email:** emeyer@fn.de

---

<div align="center">

**Built with â¤ï¸ using Python, Go, Vue 3, Wails, and llama.cpp**

â­ **Star this project if you like it!**

</div>
