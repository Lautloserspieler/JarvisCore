# ğŸ™ï¸ JarvisCore Voice Setup & Implementation Guide

## ğŸ› In dieser Guide

- [Schnellstart](#schnellstart)
- [Voice Samples erklÃ¤rt](#voice-samples-erklÃ¤rt)
- [TTS Konfiguration](#tts-konfiguration)
- [Troubleshooting](#troubleshooting)
- [Roadmap v1.2.0+](#roadmap-v120)

---

## ğŸš€ Schnellstart

### Die Voices sind bereits vorhanden!

JarvisCore enthÃ¤lt **vorgeklonte Voice-Samples**, die keine langwierige Berechnung erfordern:

```bash
# Repository klonen
git clone https://github.com/Lautloserspieler/JarvisCore.git
cd JarvisCore

# Setup durchfÃ¼hren
pip install -r requirements.txt
python main.py

# Die Voice-Samples sind automatisch geladen! âœ…
```

**Wo sind die Samples?**
```
models/tts/voices/
â”œâ”€â”€ Jarvis_DE.wav  # Deutsche JARVIS-Stimme (v2.2)
â”œâ”€â”€ Jarvis_EN.wav  # Englische JARVIS-Stimme (v2.2)
â””â”€â”€ README.md      # Technische Details
```

---

## ğŸ™ï¸ Voice Samples erklÃ¤rt

### Was sind "Vorgeklonte" Voice-Samples?

Bei Voice Cloning mit XTTS v2 werden normalerweise diese Schritte ausgefÃ¼hrt:

```
1. Voice-Sample laden (WAV)
   â†’ 2. XTTS Model laden (~2 GB)
   â†’ 3. Voice Latents berechnen (~2-3 Min) â³â³â³
   â†’ 4. Latents cachen
   â†’ 5. Text zu Sprache konvertieren
```

JarvisCore Ã¼berspringt Schritte 3-4:

```
1. Voice Latents sind bereits gecacht
   â†’ 2. XTTS Model laden (~2 GB)
   â†’ 3. Text zu Sprache konvertieren
```

**Resultat:** 5-7 Minuten Zeit gespart beim ersten Start! âš¡

### Technisch: Was ist in den WAV-Dateien?

```
Jarvis_DE.wav
â”œâ”€ Originalstimmen-Sample
â”œâ”€ 15 Sekunden natÃ¼rliches Deutsch
â”œâ”€ Professionelle Audio-QualitÃ¤t
â”œâ”€ 44.1 kHz, 16-bit mono
â””â”€ XTTS v2-optimiert fÃ¼r hohe QualitÃ¤t

Diese werden beim ersten Start automatisch zu Latents verarbeitet:

Jarvis_DE_latents.pt (gecacht nach 1. Nutzung)
â”œâ”€ XTTS v2 Speaker Embeddings
â”œâ”€ ~100 MB pro Sprache
â”œâ”€ Wird in cache/ gespeichert
â””â”€ Beim nÃ¤chsten Start sofort verfÃ¼gbar
```

---

## âš™ï¸ TTS Konfiguration

### Config-Datei: config.yaml

```yaml
# config/config.yaml

speech:
  # TTS Backend
  tts_backend: 'xtts'  # XTTS v2 (lokal) oder 'edge-tts' (cloud)
  
  # Vorgeklonte Voice Samples
  voice_sample_de: 'models/tts/voices/Jarvis_DE.wav'
  voice_sample_en: 'models/tts/voices/Jarvis_EN.wav'
  
  # Spracheinstellungen
  default_language: 'de'  # Deutsch als Standard
  supported_languages: ['de', 'en']
  
  # TTS Parameter
  temperature: 0.75        # KreativitÃ¤t (0.0 - 1.0)
  top_p: 0.85             # Diversity
  speed: 1.0              # Sprechgeschwindigkeit
  
  # Caching
  cache_latents: true     # Voice Latents zwischenspeichern
  cache_dir: 'data/tts/cache/'
  
  # Optimierungen
  device: 'cuda'          # 'cuda' (GPU), 'cpu', 'auto'
  num_gpt_tokens: 30      # Tokens pro Generation (30 = kÃ¼rzer, bessere QualitÃ¤t)
```

### Sprache automatisch erkennen

JarvisCore erkannt die User-Sprache automatisch:

```python
# Backend erkennt: "Hallo, wie geht es dir?"
# â†’ Sprache: Deutsch
# â†’ Nutzt: Jarvis_DE.wav
# â†’ Antwortet auf Deutsch

# User schreibt: "Hi, how are you?"
# â†’ Sprache: Englisch
# â†’ Nutzt: Jarvis_EN.wav
# â†’ Antwortet auf Englisch
```

---

## ğŸ› Troubleshooting

### Problem 1: Voice Sample nicht gefunden

```
âŒ ERROR: Voice sample not found at 'models/tts/voices/Jarvis_DE.wav'
```

**LÃ¶sung:**
```bash
# Repository neu klonen
git clone https://github.com/Lautloserspieler/JarvisCore.git

# Oder fehlende Samples herunterladen
cd JarvisCore
git lfs pull  # Wenn LFS installiert ist

# Oder manuell:
cd models/tts/voices/
# Jarvis_DE.wav und Jarvis_EN.wav hier platzieren
```

### Problem 2: Audio Quality zu schlecht

```python
# In config.yaml erhÃ¶hen:
speech:
  num_gpt_tokens: 30  # Default
  # â†’ NÃ¤chstes Mal: 35 oder 40
```

**Parameter erklÃ¤rt:**
- `20` tokens = KÃ¼rzer, schneller (hohe QualitÃ¤t aber robothaft)
- `30` tokens = Empfohlen (QualitÃ¤t + Geschwindigkeit)
- `40+` tokens = Natura, aber langsamer

### Problem 3: Zu langsam / GPU nicht genutzt

```bash
# GPU-Status prÃ¼fen
python -c "import torch; print(torch.cuda.is_available())"
# True = GPU verfÃ¼gbar
# False = CPU wird genutzt

# Falls False:
cd backend
python setup_llama.py
# und wÃ¤hle GPU-Option
```

### Problem 4: Stimme klingt zu kÃ¼nstlich

**MÃ¶gliche Ursachen:**
1. **Zu viele tokens** â†’ ErhÃ¶h die temperature (0.75 â†’ 0.85)
2. **Zu wenige tokens** â†’ ErhÃ¶h num_gpt_tokens (30 â†’ 35)
3. **Falsches Voice Sample** â†’ PrÃ¼fe config.yaml

**Fix:**
```yaml
speech:
  temperature: 0.80         # ErhÃ¶ht
  num_gpt_tokens: 35        # ErhÃ¶ht
  top_p: 0.85              # Etwas erhÃ¶ht
```

---

## ğŸ“‹ Roadmap v1.2.0+

### v1.2.0 (Q1 2026) - Voice Input/Output

#### Geplant:
- [ ] **Whisper Voice Input** - Spracherkennung
  - UnterstÃ¼tzt: Deutsch, Englisch, 96+ Sprachen
  - Multi-Language Support
  - Offline-FunktionalitÃ¤t
  
- [ ] **XTTS v2 Voice Output** - Text-zu-Sprache
  - Nutzt vorgeklonte Voice Samples
  - Real-time Streaming
  - Voice Clone Support (optional)
  
- [ ] **Desktop App (Wails)**
  - Native Windows/Linux/Mac App
  - System Tray Integration
  - Hotkey Support (z.B. Shift+Space zum Sprechen)

### v2.0.0 (Q2 2026) - Advanced Features

#### Geplant:
- [ ] **Custom Voice Cloning**
  - User kÃ¶nnen eigene Stimmen klonen
  - ~2-3 Minuten Setup-Zeit
  - Persistente Speicherung
  
- [ ] **Accent Control**
  - Deutsches Deutsch vs. Ã–sterreichisches Deutsch
  - British English vs. American English
  - etc.
  
- [ ] **Emotion Control**
  - Happy, Serious, Angry Variationen
  - Dynamische Voice Adaptation

---

## ğŸ“š Weitere Ressourcen

- **XTTS v2 Paper**: [arXiv:2406.04904](https://arxiv.org/abs/2406.04904)
- **Coqui TTS Docs**: [coqui.ai](https://coqui.ai/)
- **Main README**: [JarvisCore README.md](../README.md)
- **FAQ**: [FAQ.md](../FAQ.md)

---

<div align="center">

**Voice Features powered by XTTS v2 & Coqui TTS**

ğŸ† Powered by JarvisCore v1.1.0

</div>
